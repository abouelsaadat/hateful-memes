{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfc1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '84291', 'img': 'img/84291.png', 'label': 1, 'text': \"housing, free gas, free electricity, free healthcare and free education for my wives and children. to show graditude for your generosity, i'll groom your 12 year old daughters, blow up your trains, planes and buses and preach hate through a dawah stall in your local city and town centres with the purpose of turning your generous country into the same shithole i originally took refuge from, allahu akbar!\"}\n",
      "\n",
      "=== Split: train ===\n",
      "Samples: 8500\n",
      "Min length:       3\n",
      "Max length:       88\n",
      "Mean length:      16.57\n",
      "Median length:    15.00\n",
      "Std deviation:    8.86\n",
      "95th percentile:  33.00\n",
      "99th percentile:  46.00\n",
      "\n",
      "=== Split: validation ===\n",
      "Samples: 1040\n",
      "Min length:       3\n",
      "Max length:       54\n",
      "Mean length:      13.60\n",
      "Median length:    12.00\n",
      "Std deviation:    7.12\n",
      "95th percentile:  26.00\n",
      "99th percentile:  42.22\n",
      "\n",
      "=== Split: test ===\n",
      "Samples: 3000\n",
      "Min length:       3\n",
      "Max length:       74\n",
      "Mean length:      13.67\n",
      "Median length:    12.00\n",
      "Std deviation:    6.68\n",
      "95th percentile:  26.00\n",
      "99th percentile:  36.00\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset + tokenizer\n",
    "# -------------------------------\n",
    "dataset = load_dataset(\"neuralcatcher/hateful_memes\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# -------------------------------\n",
    "# Function to compute token lengths\n",
    "# -------------------------------\n",
    "def get_length_stats(split):\n",
    "    lengths = []\n",
    "\n",
    "    for row in dataset[split]:\n",
    "        text = row[\"text\"]\n",
    "        tokens = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,   # CLS + SEP\n",
    "            truncation=False,          # DO NOT truncate here\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        if len(tokens) >= 88:\n",
    "            print(row)\n",
    "        lengths.append(len(tokens))\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "\n",
    "    print(f\"\\n=== Split: {split} ===\")\n",
    "    print(f\"Samples: {len(lengths)}\")\n",
    "    print(f\"Min length:       {lengths.min()}\")\n",
    "    print(f\"Max length:       {lengths.max()}\")\n",
    "    print(f\"Mean length:      {lengths.mean():.2f}\")\n",
    "    print(f\"Median length:    {np.median(lengths):.2f}\")\n",
    "    print(f\"Std deviation:    {lengths.std():.2f}\")\n",
    "    print(f\"95th percentile:  {np.percentile(lengths, 95):.2f}\")\n",
    "    print(f\"99th percentile:  {np.percentile(lengths, 99):.2f}\")\n",
    "\n",
    "    return lengths\n",
    "\n",
    "# -------------------------------\n",
    "# Run for all splits HF provides\n",
    "# -------------------------------\n",
    "for split in dataset.keys():\n",
    "    get_length_stats(split)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
