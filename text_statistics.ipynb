{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac0d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split: train\n",
      "  Label 0: 5481 (64.48%)\n",
      "  Label 1: 3019 (35.52%)\n",
      "\n",
      "Split: validation\n",
      "  Label 1: 247 (38.59%)\n",
      "  Label 0: 393 (61.41%)\n",
      "\n",
      "Split: test\n",
      "  Label 1: 1240 (41.33%)\n",
      "  Label 0: 1760 (58.67%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"neuralcatcher/hateful_memes\")\n",
    "# Remove duplicates\n",
    "for i_split, i_data in dataset.items():\n",
    "    dataset[i_split] = Dataset.from_pandas(\n",
    "        pd.DataFrame(i_data).drop_duplicates(), preserve_index=False\n",
    "    )\n",
    "\n",
    "# Count of each class\n",
    "for split, data in dataset.items():\n",
    "    labels = data[\"label\"]           # extract list of labels\n",
    "    counts = Counter(labels)         # count occurrences\n",
    "    total = len(labels)\n",
    "\n",
    "    print(f\"\\nSplit: {split}\")\n",
    "    for label, count in counts.items():\n",
    "        print(f\"  Label {label}: {count} ({count/total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6311783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7754059478197409,\n",
       " 1.4077509108976483,\n",
       " 0.3551764705882353,\n",
       " 0.6448235294117648)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = 8500 / (2 * 5481)\n",
    "w1 = 8500 / (2 * 3019)\n",
    "w = w0+w1\n",
    "\n",
    "w0, w1, w0 / w, w1 / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cacd621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00018244845831052726,\n",
       " 0.0003312355084465055,\n",
       " 0.35517647058823526,\n",
       " 0.6448235294117647)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = 1/5481\n",
    "w1 = 1/3019\n",
    "w = w0+w1\n",
    "\n",
    "w0, w1, w0 / w, w1 / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfc1b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '84291', 'img': 'img/84291.png', 'label': 1, 'text': \"housing, free gas, free electricity, free healthcare and free education for my wives and children. to show graditude for your generosity, i'll groom your 12 year old daughters, blow up your trains, planes and buses and preach hate through a dawah stall in your local city and town centres with the purpose of turning your generous country into the same shithole i originally took refuge from, allahu akbar!\"}\n",
      "\n",
      "=== Split: train ===\n",
      "Samples: 8500\n",
      "Min length:       3\n",
      "Max length:       88\n",
      "Mean length:      16.57\n",
      "Median length:    15.00\n",
      "Std deviation:    8.86\n",
      "95th percentile:  33.00\n",
      "99th percentile:  46.00\n",
      "\n",
      "=== Split: validation ===\n",
      "Samples: 640\n",
      "Min length:       3\n",
      "Max length:       54\n",
      "Mean length:      13.86\n",
      "Median length:    12.00\n",
      "Std deviation:    7.20\n",
      "95th percentile:  28.00\n",
      "99th percentile:  40.61\n",
      "\n",
      "=== Split: test ===\n",
      "Samples: 3000\n",
      "Min length:       3\n",
      "Max length:       74\n",
      "Mean length:      13.67\n",
      "Median length:    12.00\n",
      "Std deviation:    6.68\n",
      "95th percentile:  26.00\n",
      "99th percentile:  36.00\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# -------------------------------\n",
    "# Function to compute token lengths\n",
    "# -------------------------------\n",
    "def get_length_stats(split):\n",
    "    lengths = []\n",
    "\n",
    "    for row in dataset[split]:\n",
    "        text = row[\"text\"]\n",
    "        tokens = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,   # CLS + SEP\n",
    "            truncation=False,          # DO NOT truncate here\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        if len(tokens) >= 88:\n",
    "            print(row)\n",
    "        lengths.append(len(tokens))\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "\n",
    "    print(f\"\\n=== Split: {split} ===\")\n",
    "    print(f\"Samples: {len(lengths)}\")\n",
    "    print(f\"Min length:       {lengths.min()}\")\n",
    "    print(f\"Max length:       {lengths.max()}\")\n",
    "    print(f\"Mean length:      {lengths.mean():.2f}\")\n",
    "    print(f\"Median length:    {np.median(lengths):.2f}\")\n",
    "    print(f\"Std deviation:    {lengths.std():.2f}\")\n",
    "    print(f\"95th percentile:  {np.percentile(lengths, 95):.2f}\")\n",
    "    print(f\"99th percentile:  {np.percentile(lengths, 99):.2f}\")\n",
    "\n",
    "    return lengths\n",
    "\n",
    "# -------------------------------\n",
    "# Run for all splits HF provides\n",
    "# -------------------------------\n",
    "for split in dataset.keys():\n",
    "    get_length_stats(split)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
