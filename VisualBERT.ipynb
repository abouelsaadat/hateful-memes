{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAuZH7U1zRtZ",
        "outputId": "d918e3f1-4b07-47c4-9db3-c7b3d507d220"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmuBpKaYw7ZG",
        "outputId": "616936c1-6ec1-40eb-eb28-ae4cbc36caab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/cs7643')\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vILNx-ewVFRZ",
        "outputId": "5967eca7-b4f1-4016-c77c-ac3e0c23bed1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "# URL of the Hateful Memes features archive\n",
        "URL = \"https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz\"\n",
        "TAR_PATH = \"features_2020_10_01.tar.gz\"\n",
        "EXTRACT_DIR = \"detectron.lmdb\"\n",
        "\n",
        "# 1. Download the tar.gz file (if not already downloaded)\n",
        "if not os.path.exists(TAR_PATH):\n",
        "    print(f\"Downloading from {URL} ...\")\n",
        "    urllib.request.urlretrieve(URL, TAR_PATH)\n",
        "    print(f\"Downloaded to {TAR_PATH}\")\n",
        "else:\n",
        "    print(f\"{TAR_PATH} already exists, skipping download.\")\n",
        "\n",
        "# 2. Extract the tar.gz file (if not already extracted)\n",
        "if not os.path.exists(EXTRACT_DIR):\n",
        "    print(f\"Extracting {TAR_PATH} ...\")\n",
        "    with tarfile.open(TAR_PATH, \"r:gz\") as tar:\n",
        "        tar.extractall()\n",
        "    print(f\"Extraction complete. Files are in: {EXTRACT_DIR}/\")\n",
        "else:\n",
        "    print(f\"{EXTRACT_DIR}/ already exists, skipping extraction.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4R0aSgjVfn7",
        "outputId": "e2246042-9573-4e6a-af93-0010afaff7d9"
      },
      "outputs": [],
      "source": [
        "!pip install lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtnT7Sw3RTzL"
      },
      "outputs": [],
      "source": [
        "import lmdb\n",
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class HatefulMemesDataset(Dataset):\n",
        "    def __init__(self, hf_split, lmdb_path, tokenizer):\n",
        "        \"\"\"\n",
        "        hf_split: one split from the HF DatasetDict (e.g. hf_ds['train'])\n",
        "        lmdb_env: opened lmdb.Environment\n",
        "        tokenizer: HuggingFace tokenizer (optional)\n",
        "        \"\"\"\n",
        "        self.data = hf_split\n",
        "        self.lmdb_path = lmdb_path\n",
        "        self.env = None\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _get_image_id(self, img_path):\n",
        "        # \"img/40259.png\" -> \"40259\"\n",
        "        return img_path.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    def _load_visual_feats(self, img_id):\n",
        "        if self.env is None: # opened separately in each worker\n",
        "            self.env = lmdb.open(\n",
        "                self.lmdb_path,\n",
        "                readonly=True,\n",
        "                lock=False,\n",
        "                readahead=False,\n",
        "                meminit=False\n",
        "            )\n",
        "        with self.env.begin(write=False) as txn:\n",
        "            buf = txn.get(img_id.encode(\"utf-8\"))\n",
        "            sample = pickle.loads(buf)\n",
        "        feats = torch.tensor(\n",
        "            sample[\"features\"], dtype=torch.float32\n",
        "        )  # (num_boxes, 2048)\n",
        "        bbox = torch.tensor(sample[\"bbox\"], dtype=torch.float32)  # (num_boxes, 4)\n",
        "        return feats, bbox\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data[idx]\n",
        "        text = row[\"text\"]\n",
        "        img_path = row[\"img\"]\n",
        "        label = row[\"label\"]\n",
        "\n",
        "        img_id = self._get_image_id(img_path)\n",
        "        visual_embeds, _ = self._load_visual_feats(img_id)\n",
        "\n",
        "        encoded = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=48,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
        "            \"token_type_ids\": encoded[\"token_type_ids\"].squeeze(0),\n",
        "            \"visual_embeds\": visual_embeds,\n",
        "            \"visual_attention_mask\": torch.ones(\n",
        "                visual_embeds.size(0), dtype=torch.long\n",
        "            ),\n",
        "            \"visual_token_type_ids\": torch.zeros(\n",
        "                visual_embeds.size(0), dtype=torch.long\n",
        "            ),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX98qNSCRTrv",
        "outputId": "22ef7d1a-c7a3-4c63-9371-75eab522a76e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import VisualBertModel, VisualBertConfig, BertTokenizer\n",
        "\n",
        "lmdb_path = \"detectron.lmdb\"\n",
        "dataset = load_dataset(\"neuralcatcher/hateful_memes\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    HatefulMemesDataset(dataset[\"train\"], lmdb_path, tokenizer),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ALB6LcS5h2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import VisualBertModel\n",
        "\n",
        "class VisualBertForClassification(nn.Module):\n",
        "    def __init__(self, num_labels=2):\n",
        "        super().__init__()\n",
        "        self.visualbert = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
        "        hidden_size = self.visualbert.config.hidden_size  # usually 768\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids,\n",
        "        attention_mask,\n",
        "        token_type_ids,\n",
        "        visual_embeds,\n",
        "        visual_attention_mask,\n",
        "        visual_token_type_ids,\n",
        "    ):\n",
        "        outputs = self.visualbert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            visual_embeds=visual_embeds,\n",
        "            visual_attention_mask=visual_attention_mask,\n",
        "            visual_token_type_ids=visual_token_type_ids,\n",
        "        )\n",
        "\n",
        "        pooled = outputs.pooler_output  # (B, 768)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXCoCoTkV0Cu",
        "outputId": "e5bcd2be-e140-4931-fba5-d723a8b7de45"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "model = VisualBertForClassification().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi4Bzq8WRTiG"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(10):  # number of epochs\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loader_train:\n",
        "        # Move everything to the GPU\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass through YOUR classifier model\n",
        "        logits = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            token_type_ids=batch[\"token_type_ids\"],\n",
        "            visual_embeds=batch[\"visual_embeds\"],\n",
        "            visual_attention_mask=batch[\"visual_attention_mask\"],\n",
        "            visual_token_type_ids=batch[\"visual_token_type_ids\"],\n",
        "        )\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, batch[\"label\"])\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
